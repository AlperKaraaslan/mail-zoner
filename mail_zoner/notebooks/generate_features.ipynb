{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Append SYS path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "sys.path.append(r\"c:\\Users\\alper.karaaslan\\Documents\\VisualStudioRepos\\ml-classification-preprocessing-email-zone\")\n",
    "\n",
    "HOMEDIR = pathlib.Path.cwd().parent.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Webis Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mail_zoner.functions.preprocessing_webis import Preprocess_webis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir_train = HOMEDIR / 'data_webis' / 'annotations-final-train.jsonl'\n",
    "data_dir_val = HOMEDIR / 'data_webis' / 'annotations-final-validation.jsonl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduce_dataset=False #chose a smaller subset of the whole dataset\n",
    "N_reduced_emails=4 #how many emails to chose, when reduce_dataset=True\n",
    "remove_long_mails = True #discard mails longer than MAXLENMAIL\n",
    "test_split=0.33 #train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reorder data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & Test set\n",
    "preprocessor_webis_train = Preprocess_webis(jsonldir=data_dir_train,reduced=reduce_dataset,N_reduced=N_reduced_emails,remove_long_mails=remove_long_mails,test_split=test_split)\n",
    "dataset_train_webis,dataset_test_webis = preprocessor_webis_train.reorder_data()\n",
    "\n",
    "\n",
    "# Validation set\n",
    "preprocessor_webis_val = Preprocess_webis(jsonldir=data_dir_val,reduced=reduce_dataset,N_reduced=N_reduced_emails,remove_long_mails=remove_long_mails,test_split=None)\n",
    "dataset_val_webis,_ = preprocessor_webis_val.reorder_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mail_zoner.functions.tokenizer import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "dataset_train_webis_tokenized = tokenizer.tokenize_dataset(dataset_train_webis)\n",
    "dataset_val_webis_tokenized = tokenizer.tokenize_dataset(dataset_val_webis)\n",
    "dataset_test_webis_tokenized = tokenizer.tokenize_dataset(dataset_test_webis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at jplu/tf-xlm-roberta-base were not used when initializing TFXLMRobertaModel: ['lm_head']\n",
      "- This IS expected if you are initializing TFXLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFXLMRobertaModel were initialized from the model checkpoint at jplu/tf-xlm-roberta-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFXLMRobertaModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from mail_zoner.functions.generate_features import encoder_xlmroberta\n",
    "encoder = encoder_xlmroberta()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "savedir_features = HOMEDIR / 'data_webis' / 'features'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Saving train features\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [05:26<00:00, 163.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Saving val features\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [04:32<00:00, 68.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "Saving test features\n",
      "**********\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [07:06<00:00, 213.50s/it]\n"
     ]
    }
   ],
   "source": [
    "from mail_zoner.functions.generate_features import save_features\n",
    "\n",
    "save_features(encoder,dataset_train_webis_tokenized,savedir=savedir_features,subfolder='train')\n",
    "save_features(encoder,dataset_val_webis_tokenized,savedir=savedir_features,subfolder='val')\n",
    "save_features(encoder,dataset_test_webis_tokenized,savedir=savedir_features,subfolder='test')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "255fc6da8029bef322b6bca02b59f88e093370c5ed0c5392c887dcd3df5b3dfc"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('ml-classification-preprocessing-email-zone-3e72BEgC-py3.8': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
